# 자료구조와 알고리즘의 이해

## 자료구조의 이해

### 자료구조를 공부하기 전

C언어와 관련하여 알고 있다고 가정하는 부분

- 구조체를 정의할 줄 안다. (구현 관련)
- 메모리의 동적 할당과 관련하여 이해한다.
- 포인터와 관련하여 이해와 활용에 부담이 없다.
- 헤더파일의 정의하고 활용할 줄 안다. (구현 관련)
- 각종 매크로를 이해하고 #ifndef ~ #endif의 의미를 안다.
- 다수의 소스파일, 헤더파일로 구성된 프로그램 작성 가능 (구현 관련)
- 재귀함수에 어느 정도 익숙하다.

### 자료구조란

> "프로그램이란 데이터를 표현하고, 그렇게 표현된 데이터를 처리하는 것이다."

 '데이터의 표현'은 '데이터의 저장'을 포함하는 개념으로 데이터의 표현 및 저장방법이 자료구조이다.  이때 표현 및 저장된 데이터를 대상으로 하는 '문제의 해결 방법'을 알고리즘이라고 한다. 알고리즘은 자료구조에 의존적이다.

#### 자료구조의 분류

![0001](https://user-images.githubusercontent.com/54986748/75147295-4e376c80-5740-11ea-94af-e83de617cb18.jpg)

- 선형 자료구조 : 자료를 표현 및 저장하는 방식이 선형(linear)이다. 데이터를 선의 형태로 나란히 혹은 일렬로 저장하는 방식.
- 비선형 자료구조 : 데이터를 나란히 저장하지 않는 구조이다.



## 알고리즘의 성능 분석

### 수학 관련 내용

<img src="https://user-images.githubusercontent.com/54986748/75149716-01569480-5746-11ea-9673-e912e6cc33d8.png" alt="002" style="zoom:50%;" />

- 지수식 y = 2^x
- 로그식 y = log₂x

### 시간 복잡도와 공간 복잡도

#### 알고리즘을 평가하는 두 가지 요소

- 시간 복잡도(Time Complexity) : 알고리즘의 수행시간 분석결과(얼마나 빠른가)
- 공간 복잡도(Space complexity) :  메모리 사용량에 대한 분석결과(얼마나 메모리를 적게 쓰는가)
- 시간 복잡도를 더 중요시 한다. 
  - 메모리에 접근에 따른 시간이 증가하기 때문에 공간 복잡도 또한 생각해 보자는 것으로 공간복잡도의 문제는 시간에 귀결 된다.
  - 메모리를 적게 쓰고 속도도 빨라야 최적의 알고리즘이라고 할 수 있다.

#### 시간 복잡도의 평가 방법

- 중심이 되는 특정 연산의 횟수를 세어서 평가를 한다.
- 데이터의 수 n에 대한 연산횟수의 함수 T(n)을 구한다. 
  - 데이터의 수를 함수에 입력하면 연산의 횟수가 바로 계산 되는 식을 구성한다는 의미로 식을 구성하면 데이터 수의 증가에 따른 연산횟수의 변화 정도를 판단할 수 있다.

#### 알고리즘의 수행 속도 비교 기준

<img src="https://user-images.githubusercontent.com/54986748/75149749-0f0c1a00-5746-11ea-85c4-8d9c2946d755.png" alt="003" style="zoom:67%;" />

위 그림은 동일한 기능을 제공하는 서로 다른 두 알고리즘의 성능을 비교한 결과이다. 데이터 수가 적으면 알고리즘 B가 빠르고 늘어나면 A가 더 빠른 결과를 확인 할 수 있다. 이때 데이터의 수가 적은 경우에는 B를 많은 경우에는 A를 적용한다는 판단이 나올 수 있다. 하지만 데이터의 수가 적은 경우, 속도 차이는 크지 않다 중요한 것은 데이터의 수가 많아짐에 따른 연산 횟수의 증가 정도에 있다.

그렇다면 알고리즘 A만 사용해야 하는 걸까? A가 구현의 난도가 높고 데이터의 수가 많지 않고 성능에 덜 민감한 경우라면 B의 알고리즘을 택할 수도 있다. 즉, 상황에 맞게 답을 내려야 한다.

- 데이터의 수가 적은 경우의 수행 속도는 큰 의미가 없다.
- 데이터의 수에 따른 수행 속도의 변화 정도를 기준으로 한다.

### 순차 탐색 알고리즘과 시간 복잡도

```c
int LSearch(int ar[], int len, int target)
{
	int i;
	for(i=0; i<len; i++)
	{
		if(ar[i]==target)
			return i;//찾은 대상의 인덱스 값 반환
	}
	return -1; // 찾지 못했음을 의미하는 값 반환
}
```

순차적으로 탐색해 나가는 알고리즘이 순차 탐색 알고리즘이다. 위의 함수를 보면 for문으로 target이 맞는지 아닌지 비교연산을 진행하고 있다. 이 알고리즘에서 시간 복잡도를 결정할 연산자는 == 가 될 것이다. '탐색'이 중심이 되기 때문이다. 

의심이 되는 연산자를 배치해보고 무엇이 중심이 되는 연산자인지 생각해보자. 중심이 되는 연산자의 특징은 주변에 존재하는 연산자들의 연산 횟수는 중심이 되는 연산자의 연산 횟수에 의존적이다.  따라서 이 함수에서는 == 연산의 횟수를 대상으로 시간 복잡도를 분석하면 된다.

#### **최악의 경우와 최상의 경우**

- 순차 탐색 상황 하나 : 운이 좋은 경우 `T(n) =1`
  - 배열의 맨 앞에서 대상을 찾는 경우
  - 만족스러운 상황이므로 **성능평가의 주 관심이 아니다.**
  - '최상의 경우(best case)'라 한다.

시간 복잡도와 공간 복잡도 각각에 대해서 최악의 경우와 최상의 경우를 구할 수 있다.

- 순차 탐색 상황 둘 : 운이 좋지 않은 경우 `T(n) = n`
  - 배열의 끝에서 찾거나 대상이 저장되지 않은 경우
  - 만족스럽지 못한 상황이므로 성능평가의 주 관심이다.
  - '최악의 경우(worst case)'라 한다.

성능을 위한 시간 복잡도를 평가한다고 했을 때는 언제나 최악의 경우를 기준으로 한다.

#### 평군적인 경우(Average Case)

- 가장 현실적인 경우에 해당한다.
  - 일반적으로 등장하는 상황에 대한 경우의 수이다.
  - 최상의 경우와 달리 알고리즘 평가에 도움이 된다.
  - 하지만 계산하기가 어렵다. 객관적 평가가 쉽지 않다.
- 평균적인 경우의 복잡도 계산이 어려운 이유
  - '평균적인 경우'의 연출이 어렵다
  - '평균적인 경우'임을 증명하기 어렵다.
  - '평균적인 경우'는 상황에 따라 달라진다. 반면 최악의 경우는 늘 동일하다.

##### 순차 탐색 최악의 경우 시간 복잡도

> "데이터의 수가 n개일 때, 최악의 경우에 해당하는 연산횟수는(비교연산의 횟수는) n이다."

`T(n) = n`  최악의 경우를 대상으로 정의한 함수 T(n)

##### 순차 탐색 평균적인의 경우 시간 복잡도

> 가정 1 : 탐색 대상이 배열에 존재하지 않을 확률 50%
>
> 가정 2 : 배열 첫 요소부터 마지막 요소까지 탐색 대상 존재 확률 동일

- 탐색 대상이 존재하지 않는 경우의 연산 횟수는 n
- 가정 2 에 의해서 탐색 대상이 존재하는 경우의 연산횟수는 n/2

`T(n) = n x 1/2 + n/2 x 1/2 = 3/4*n`

하지만 데이터의 성격에 따라 가정 1과 가정 2는 달라진다 그렇기에 평균적 경우라고 할 수 없다. 평균적인 경우의 시간 복잡도는 최악의 경우를 구한 후 그 알고리즘의 특성을 보조적으로 사용 되는 보조적 수단은 될 수 있지만 절대적인 평가 기준이 될 수 없다.  

### 이진 탐색 알고리즘과 시간 복잡도

이진 탐색 알고리즘은 순차 탐색보다 훨씬 좋은 성능을 보이지만, 배열이 정렬되어 있어야 한다는 제약이 따른다. 이때, 정렬의 기준 및 방식과는 관계없다.

```c
int BSearch(int ar[], int len, int target)
{
	int first = 0; // 탐색 대상의 시작 인덱스 값
	int last = len - 1; // 탐색 대상의 마지막 인덱스 값
	int mid;
	
	while(first <= last)
	{
		mid = (first+last)/2 // 탐색 대상의 시작 인덱스 값
		
		if(target == ar[mid]) // 중앙에 저장된 것이 타겟이라면
		{
			return mid; // 탐색 완료!
		}
		else // 타겟이 아니라면 탐색 대상을 반으로 줄인다.
		{
			if(target < ar[mid])
				last = mid-1; // 왜 -1을 하였을까?
            else
            	first = mid+1; // 왜 +1을 하였을까?
		}
	}
	return -1; // 찾지 못했을 때 반환되는 값 -1
}
```

- first와 last가 만났다는 것은 아직 확인이 안된 탐색 대상이 하나 남았다는 것을 뜻함
- 따라서 first와 last가 역전될 때까지 탐색의 과정을 계속한다.

- -1 혹은 +1을 추가하지 않으면 first <= mid <= last 가 항성 성립이 되어, 탐색 대상이 존재하지 않는 경우 first와 last의 역전 현상이 발생하지 않는다.

#### 이진탐색 최악의 경우 시간 복잡도

이진 탐색의 시간 복잡도 계산을 위한 핵심 연산은 == 연산자이다. 따라서 == 연산자의 연산 횟수를 기준으로 시간 복잡도를 결정할 수 있다. 

이때 데이터의 수가 n개일 때, 최악의 경우에 발생하는 비교연산의 횟수는 어떻게 되는가? 이에 대한 답은 비교연산의 횟수는 딱 떨어지게 말할 수 없다. n이 얼마인지 결정 되지 않았으니 이 사이에 도대체 몇 번의 비교연산이 진행되는지 알 수 없기 때문이다. 그렇다면 어떻게 해야할까

- 비교 연산의 횟수의 예
  - 8이 1이 되기까지 2로 나눈 횟수 3회 따라서 비교연산 3회 진행
  - 데이터가 1개 남았을 때, 이때 마지막으로 비교연산 1회 진행
- 비교 연산의 횟수의 일반화
  - n이 1이 되기까지 2로 나눈 횟수 k회, 따라서 비교연산 k회 진행
  - 데이터가 1개 남았을 때, 이때 마지막으로 비교연산 1회 진행
- 비교 연산의 횟수의 1차 결론
  - 최악의 경우에 대한 시간 복잡도 함수 `T(n) = k+1`  이때 k를 구해야한다.

`nx(1/2)^k = 1`  :  n을 몇번 반으로 나눠야 1이 되는가? k가 나눠야 하는 횟수를 말한다.

`nx(1/2)^k = 1` ▶ `n x 2^-k = 1` ▶ `n = 2^k` 

`n = 2^k` ▶  `log₂n = log₂2^k` ▶ `log₂n = k log₂2` ▶  `log₂n = k` 

##### **결론**

- 함수 T(n) = k+1 이므로 T(n) = log₂n+1
- 시간 복잡도의 목적은 n의 값에 따른 T(n)의 증가 및 감소의 정도를 판단하는 것이므로 +1은 생략이 가능하다 따라서 `T(n) = log₂n`

### 빅-오 표기법(Big-oh Notation)

 T(n)에서 실제로 영향력을 끼치는 부분을 가리켜 빅-오(Big-Oh)라 한다. 

T(n) = n² + 2n+1  / 1차 근사치 식 ▶  T(n) =  n² + 2n / 2차 근사치 식  ▶   T(n) =  n²  ▶   O(n²) / T(n)의 빅-오

<img src="https://user-images.githubusercontent.com/54986748/75340164-4d840f00-58d5-11ea-8815-0cacd9d9f38d.jpg" alt="0002" style="zoom:50%;" />

n이 증가함에 따라 2n+1이 차지하는 비율은 미미해진다. n²이 차지하는 비율은 절대적이다. 따라서  T(n) = n² + 2n+1 의 빅오는 n²으로  O(n²) 로 표기하며 빅-오 오브 n²(Big-Oh of  n² ) 과 같이 읽는다.

#### 단순하게 빅-오 구하기

T(n)이 다항식으로 표현이 된 경우, 최고차항의 차수가 빅-오가 된다.

#### 대표적 빅-오

<img src="https://user-images.githubusercontent.com/54986748/75340993-db142e80-58d6-11ea-8f3a-f8e6f81aecdf.jpg" alt="0003" style="zoom:50%;" />

- O(1)

상수형 빅-오라 하며 데이터 수에 상관 없이 연산횟수가 고정인 유형의 알고리즘을 뜻한다.

- O(log n)

로그형 빅-오라 하며 '데이터 수의 증가율'에 비해서 '연산횟수의 증가율'이 훨씬 낮은 알고리즘을 의미한다. 따라서 좋은 성능을 보이며 매우 바람직한 유형이라고 할 수 있다. 로그 밑이 얼마인가에 따라 차이가 생기지만 그 차이는 알고리즘 성능 관점에서는 매우 미미하다.

- O(n)

선형 빅-오라 하며 데이터의 수와 연산횟수가 비례하는 알고리즘이다.

- O(n log n)

선형로그형 빅-오라 하며 데이터 수가 두 배로 늘 때, 연산횟수는 두 배를 조금 넘게 증가하는 알고리즘을 의미한다.

- O(n²)

데이터 수의 제곱에 해당하는 연산횟수를 요구하는 알고리즘이다. 데이터의 양이 많은 경우에는 적용하기 부적절하며 중첩된 반복문 내에서 알고리즘에 관련된 연산이 진행되는 경우 발생한다.

- O(n³)

데이터 수의 세 제곱에 해당하는 연산횟수를 요구하는 알고리즘을 의미한다. 삼중으로 중첩된 반복문 내에서 알고리즘에 관련된 연산이 진행되는 경우 발생한다.

#### 순차 탐색 알고리즘과 이진 탐색 알고리즘의 비교

- 순차 탐색의 최악의 경우 시간 복잡도는 T(n) = n 이므로 빅- 오는 O(n)
- 이진 탐색의 최악의 경우 시간 복잡도는 T(n) = log₂n+1 이므로 빅-오는 O(log n)

#### 빅-오에 대한 수학적 접근

- 빅-오의 수학적 정의

두 개의 함수 f(n)과 g(n)이 주어졌을때, 모든 n ≥K에 대하여 f(n)≤ Cg(n)을 만족하는 두 개의 상수  C와 K가 존재하면, f(n)의 빅-오는 O(g(n))이다.

앞서 빅-오의 개념은 데이터 수의 증가에 따른 연산횟수의 증가 형태를 표현한 것으로 설명했는데 수학적 접근으로 본다면 데이터 수의 증가에 따른 연산횟수 증가율의 상한선을 표현한 것을 빅-오라고 할 수 있다.



> Reference
>
> - 윤성우의 열혈 자료구조

